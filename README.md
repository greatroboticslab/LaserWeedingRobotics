# Autonomous Laser Weed Control System

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![YOLOv11](https://img.shields.io/badge/YOLOv11-Ultralytics-orange.svg)](https://github.com/ultralytics/ultralytics)

## ğŸŒ¾ Overview

This project presents a comprehensive **Autonomous Laser Weed Control System** that combines artificial intelligence, precision laser technology, and robotic navigation for automated agricultural weed management. The system uses deep learning-based computer vision to identify weeds and precisely targets them with laser technology, offering an eco-friendly alternative to chemical herbicides.

## ğŸ¯ Key Features

- **ğŸ¤– AI-Powered Weed Detection**: YOLOv11-based deep learning model for real-time weed identification
- **ğŸ¯ Precision Laser Control**: High-accuracy laser targeting system with dual-motor control
- **ğŸ§­ Autonomous Navigation**: GPS and IMU-based navigation with real-time positioning
- **ğŸ® Multi-Interface Control**: Web interface, gamepad control, and manual operation modes
- **ğŸ“¡ Real-time Communication**: MQTT-based data exchange and monitoring
- **âš¡ Edge Computing**: Optimized for Jetson Nano and Raspberry Pi deployment

- ## ğŸ†• Latest Updates (v2.0 - October 2025)
**Major enhancements to the predictive targeting system:**
- ğŸ® FlySky remote control integration with 4 operation modes
- âš¡ Dual motor synchronized laser tracking  
- ğŸ§  Intelligent area filtering (91% reduction in false positives)
- ğŸ¯ Two-phase static targeting system (AIMING â†’ FIRING)
- ğŸ“¡ ESP32 dual-core optimization (<10ms system latency)

See [Predictive Aim README](Laser_System/predictiveaim/) for detailed technical documentation.

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AI Vision     â”‚    â”‚  Laser Control  â”‚    â”‚   Navigation    â”‚
â”‚   (Jetson Nano) â”‚â—„â”€â”€â–ºâ”‚   (ESP32 +      â”‚â—„â”€â”€â–ºâ”‚ (Raspberry Pi)  â”‚
â”‚                 â”‚    â”‚    Helios DAC)  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MQTT Communication Hub                      â”‚
â”‚                    (Central Coordinator)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
lasergithub/
â”œâ”€â”€ Laser_System/                    # Laser control and targeting
â”‚   â”œâ”€â”€ calibration and test/        # System calibration tools
â”‚   â”‚   â”œâ”€â”€ calibration.py          # Laser-camera calibration
â”‚   â”‚   â””â”€â”€ doublelasertest.py      # Dual laser testing
â”‚   â”œâ”€â”€ predictiveaim/              # Predictive targeting
â”‚   â”‚   â””â”€â”€ predictiveaim.py        # Motion prediction algorithms
â”‚   â””â”€â”€ lasercar_systemï¼ˆold_versionï¼‰/ # Web interface & control
â”‚       â”œâ”€â”€ app.py                  # Flask web application
â”‚       â”œâ”€â”€ esp32_robot_control.ino # ESP32 firmware
â”‚       â”œâ”€â”€ static/                 # Web assets
â”‚       â””â”€â”€ templates/              # HTML templates
â”œâ”€â”€ Yolo/                           # AI vision system
â”‚   â”œâ”€â”€ code/                       # Training and data management
â”‚   â”‚   â”œâ”€â”€ fine_tuning.py         # YOLOv11 model fine-tuning
â”‚   â”‚   â””â”€â”€ weed_lable_update_download.py # Roboflow integration
â”‚   â””â”€â”€ finetuned_trinning_result/  # Training results and metrics
â””â”€â”€ auto_navigation/                # Navigation and positioning
    â”œâ”€â”€ jetsonnano/                 # Jetson Nano deployment
    â””â”€â”€ resberry pi/                # Raspberry Pi IMU/GPS
```

## ğŸ”§ Hardware Requirements

### Core Components
- **Jetson Nano**: AI inference and computer vision processing
- **Raspberry Pi 4**: IMU/GPS data collection and MQTT communication
- **ESP32**: Motor control and laser system coordination
- **Helios Laser DAC**: High-precision laser positioning control
- **BerryIMU**: 9-axis IMU sensor for orientation and movement tracking
- **USB Camera**: Real-time video capture for weed detection

### Laser System
- Dual-motor galvanometer system for XY laser positioning
- Laser diode with adjustable power control
- Safety interlocks and emergency stop mechanisms

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/laser-weed-control.git
cd laser-weed-control

# Install Python dependencies
pip install ultralytics opencv-python flask paho-mqtt numpy scipy

# Install additional requirements for each subsystem
pip install -r requirements.txt
```

### 2. Hardware Configuration

#### Jetson Nano Setup
```bash
# Enable GPU performance mode
sudo nvpmodel -m 0
sudo jetson_clocks

# Start Docker container for YOLO inference
sudo docker start yolov11n
sudo docker exec -it yolov11n /bin/bash
```

#### Raspberry Pi Setup
```bash
# Install IMU libraries
sudo apt-get install python3-dev python3-pip
pip3 install paho-mqtt gpsd-py3

# Enable I2C and GPS
sudo raspi-config
```

### 3. System Calibration

```bash
# Run laser-camera calibration
cd Laser_System/calibration\ and\ test/
python calibration.py

# Test dual laser system
python doublelasertest.py
```

### 4. Start the System

```bash
# Terminal 1: Start web interface
cd Laser_System/lasercar_systemï¼ˆold_versionï¼‰/
python app.py

# Terminal 2: Start navigation system
cd auto_navigation/resberry\ pi/
python3 berryIMU_mqtt.py

# Terminal 3: Start AI inference (on Jetson Nano)
python3 weed4.py
```

## ğŸ¤– AI Model Training

### Dataset Preparation
The system uses YOLOv11 for weed detection with custom dataset integration via Roboflow:

```bash
cd Yolo/code/
python weed_lable_update_download.py  # Download and manage datasets
python fine_tuning.py                 # Train custom model
```

### Model Performance
- **mAP@0.5**: Achieved high accuracy on custom weed dataset
- **Real-time Inference**: Optimized for edge deployment
- **Custom Classes**: Trained specifically for agricultural weed species

## ğŸ® Control Interfaces

### Web Interface
- **Real-time Monitoring**: Live camera feed with detection overlays
- **Manual Control**: Direct laser positioning and power control
- **System Status**: Hardware health and performance metrics
- **Safety Controls**: Emergency stop and laser disable functions

### Gamepad Control
- **Dual Stick Control**: Precise manual positioning
- **Button Mapping**: Quick access to common functions
- **Safety Lockouts**: Prevents accidental laser activation

## ğŸ›¡ï¸ Safety Features

- **Hardware Emergency Stop**: Physical kill switch for immediate shutdown
- **Software Interlocks**: Multiple layers of safety validation
- **Laser Power Limiting**: Configurable maximum power levels
- **Motion Detection**: Automatic shutdown on unexpected movement
- **Timeout Protection**: Automatic shutdown after inactivity

## ğŸ“Š Performance Metrics

- **Detection Accuracy**: >95% weed identification rate
- **Targeting Precision**: Sub-millimeter laser positioning
- **Processing Speed**: Real-time operation at 20+ FPS
- **Coverage Rate**: Configurable scan patterns and speeds

## ğŸ”¬ Research Applications

This system serves as a platform for research in:
- **Precision Agriculture**: Sustainable farming practices
- **Computer Vision**: Agricultural object detection and classification
- **Robotics**: Autonomous navigation and manipulation
- **Laser Applications**: Non-contact material processing

## ğŸ¤ Contributing

We welcome contributions from the research community! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details on:
- Code style and standards
- Testing procedures
- Documentation requirements
- Submission process

## ğŸ“š Publications & Citations

If you use this system in your research, please cite:
```bibtex
@misc{laser_weed_control_2024,
  title={Autonomous Laser Weed Control System},
  author={[Your Name]},
  year={2024},
  howpublished={\url{https://github.com/yourusername/laser-weed-control}}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Ultralytics**: YOLOv11 framework and community support
- **Roboflow**: Dataset management and annotation tools
- **OpenCV**: Computer vision processing capabilities
- **Flask**: Web interface framework

## ğŸ“ Contact & Support

For questions, suggestions, or collaboration opportunities:
- **Issues**: [GitHub Issues](https://github.com/yourusername/laser-weed-control/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/laser-weed-control/discussions)
- **Email**: your.email@institution.edu

---


**âš ï¸ Safety Notice**: This system uses laser technology. Always follow proper safety protocols and local regulations when operating laser equipment. Ensure proper eye protection and safety barriers are in place during operation.
